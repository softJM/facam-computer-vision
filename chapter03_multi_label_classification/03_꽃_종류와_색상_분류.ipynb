{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab09a417c98e68c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part1 Chpater03_01 의류 색상 및 종류 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac150d9a6e95ebf9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 데이터 불러오기\n",
    "1) 어노테이션 파일을 불러온다.</br>\n",
    "2) 데이터의 기본 속성을 파악한다. (데이터 개수, 클래스 개수, 클래스 개수 분포 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:33:06.729710Z",
     "start_time": "2024-03-15T02:33:06.707700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "'''\n",
    "    어노테이션 파일을 불러온다.\n",
    "'''\n",
    "\n",
    "def xml_parsing(xml_path):\n",
    "    filename_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    # XML 파일 불러오기\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # 이미지 파일명과 라벨 추출\n",
    "    for image in root.findall('image'):\n",
    "        filename = image.find('filename').text\n",
    "        filename_list.append(filename)\n",
    "        \n",
    "        labels = [label.text for label in image.find('labels')]\n",
    "        label_list.append(labels)\n",
    "    \n",
    "    return filename_list, label_list\n",
    "\n",
    "data_root = './part1_chapter03_03'\n",
    "image_dir = 'images'\n",
    "annotation_filename = 'annotations.xml'\n",
    "annotation_path = os.path.join(data_root, annotation_filename)\n",
    "\n",
    "filename_list, label_list = xml_parsing(annotation_path)\n",
    "print(filename_list[:2])\n",
    "print(label_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11630b83ba4187c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:33:17.498766Z",
     "start_time": "2024-03-15T02:33:17.480339Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "'''\n",
    "    데이터의 기본 속성을 파악한다. (데이터 개수, 클래스 개수, 클래스 개수 분포 등)\n",
    "'''\n",
    "\n",
    "def get_class_map(label_list):\n",
    "    cls_map = defaultdict(int)\n",
    "    for labels in label_list:\n",
    "        for l in labels: \n",
    "            cls_map[l] += 1\n",
    "\n",
    "    return cls_map\n",
    "\n",
    "cls_map = get_class_map(label_list)\n",
    "cls_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709d12a9b9aff4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:33:29.719380Z",
     "start_time": "2024-03-15T02:33:29.701180Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "    pandas Dataframe으로 어노테이션 테이블 생성\n",
    "'''\n",
    "\n",
    "class_list = list(cls_map.keys())\n",
    "columns = ['filename'] + class_list\n",
    "annotations = pd.DataFrame(columns=columns)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7179caa8f06d039",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:33:43.999688Z",
     "start_time": "2024-03-15T02:33:43.581973Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, (filename, labels) in enumerate(zip(filename_list, label_list)):\n",
    "    row = {}\n",
    "    row['filename'] = filename\n",
    "    \n",
    "    for cls in class_list:\n",
    "        if cls in labels:\n",
    "            row[cls] = 1\n",
    "        else:\n",
    "            row[cls] = 0\n",
    "    annotations.loc[idx] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8342bf202614880",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:33:45.017358Z",
     "start_time": "2024-03-15T02:33:44.999186Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotations = annotations.sample(frac=1).reset_index(drop=True)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85736d537627db43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:31:20.996642Z",
     "start_time": "2024-03-14T13:31:19.750870Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99b7e927fec21625",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. 데이터 시각화\n",
    " 1) 어노테이션을 랜덤으로 섞는다.</br>\n",
    " 2) 전체 데이터 샘플을 시각화 한다.</br>\n",
    " 3) 클래스별 데이터 샘플을 시각화 한다.데이터 샘플을 시각화 하여 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed51a349393e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:34:12.190214Z",
     "start_time": "2024-03-15T02:34:12.160247Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    이미지 시각화 함수를 정의한다. \n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_images(images, classes):\n",
    "    '''\n",
    "        :param images: cv2(ndarray) 이미지 리스트\n",
    "        :param classes: 클래스 리스트\n",
    "        :return: None \n",
    "    '''\n",
    "    # 4x2의 그리드 생성 (바둑판 이미지 틀 생성)\n",
    "    fig, axs = plt.subplots(2, 4)\n",
    "    \n",
    "    # 각 하위 그래프에 이미지 출력\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        ax.imshow(images[i]) # 이미지를 바둑판에 출력\n",
    "        ax.set_title(classes[i]) # 클래스 이름으로 이미지 제목 생성 \n",
    "        # ax.axis('off') # 축 숨기기\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af1033242ef1daf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:34:26.992275Z",
     "start_time": "2024-03-15T02:34:25.784914Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "'''\n",
    "    데이터를 랜덤하게 셔플하고 시각화를 수행한다.\n",
    "'''\n",
    "\n",
    "annotations = annotations.sample(frac=1).reset_index(drop=True)\n",
    "sample_images = [] # 이미지 샘플 저장\n",
    "sample_classes = [] # 이미지 클래스 저장\n",
    "sample_cnt = 0 # 시작 count\n",
    "max_cnt = 8 # 종류 count\n",
    "for idx, annot in annotations.iterrows():\n",
    "    classes = []\n",
    "    for cls in class_list:\n",
    "        if int(annot[cls]) == 1:\n",
    "            classes.append(cls)\n",
    "    sample_classes.append(classes)\n",
    "    image_path = os.path.join(data_root, image_dir, annot['filename'])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    sample_images.append(np.array(image))\n",
    "    sample_cnt += 1\n",
    "    if sample_cnt == max_cnt:\n",
    "        break\n",
    "\n",
    "## 전체 데이터 샘플을 시각화 한다.\n",
    "draw_images(sample_images, sample_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90330d73c1ded4f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:34:32.215959Z",
     "start_time": "2024-03-15T02:34:31.809780Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "'''\n",
    "    클래스별 데이터를 시각화 한다.\n",
    "'''\n",
    "\n",
    "annotations = annotations.sample(frac=1).reset_index(drop=True)\n",
    "find_cls = ['rose', 'red']\n",
    "sample_images = [] # 이미지 샘플 저장\n",
    "sample_classes = [] # 이미지 클래스 저장\n",
    "sample_cnt = 0 # 시작 count\n",
    "max_cnt = 8 # 종류 count\n",
    "for idx, annot in annotations.iterrows():\n",
    "    classes = []\n",
    "    for cls in class_list:\n",
    "        if int(annot[cls]) == 1:\n",
    "            classes.append(cls)\n",
    "    if (classes[0] in find_cls) and (classes[1] in find_cls):  \n",
    "        sample_classes.append(classes)\n",
    "        image_path = os.path.join(data_root, image_dir, annot['filename'])\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        sample_images.append(np.array(image))\n",
    "        sample_cnt += 1\n",
    "        if sample_cnt == max_cnt:\n",
    "            break\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "## 전체 데이터 샘플을 시각화 한다.\n",
    "draw_images(sample_images, sample_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc660e1b20326f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:31:21.758232Z",
     "start_time": "2024-03-14T13:31:21.613109Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b4410bd5226d04",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3. 데이터세트 클래스 생성\n",
    "1) json 데이터를 파싱하고 출력하는 커스텀 데이터세트 클래스를 생성한다.</br>\n",
    "2) 데이터세트의 출력 값을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482199155fe113b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:34:55.100428Z",
     "start_time": "2024-03-15T02:34:55.045250Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "'''\n",
    "    csv 데이터를 파싱하는 커스텀 데이터세트 클래스를 선언한다.\n",
    "'''\n",
    "\n",
    "class CsvDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 data_root,\n",
    "                 image_dir,\n",
    "                 annotations,\n",
    "                 transform=None):\n",
    "        '''\n",
    "            :param data_root: 데이터셋의 루트 경로 \n",
    "            :param annotations: 어노테이션\n",
    "            :param transform: 이미지 변환 모듈\n",
    "        '''\n",
    "        self.data_root = data_root\n",
    "        self.image_dir = image_dir\n",
    "        self.annotations = annotations\n",
    "        self.transform = transform\n",
    "        self.class_list = self._get_classes() # 클래스의 목록\n",
    "        self.num_classes = len(self.class_list) # 클래스 개수\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations) # 데이터 개수\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "            :param idx:  \n",
    "            :return:\n",
    "                image : 입력 이미지 데이터 (텐서 또는 pillow 이미지)\n",
    "                target : 정답 클래스 데이터 (원-핫 벡터)\n",
    "                    예) [1.0, 0.0, 0.0, 1.0, 0.0, ...]\n",
    "        '''\n",
    "        annot = self.annotations.iloc[idx]\n",
    "        image_path = os.path.join(self.data_root, self.image_dir, annot['filename'])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        '''\n",
    "            원-핫 벡터를 생성한다.\n",
    "            예) [0.0, 1.0, 0.0, 0.0, 1.0, ...]\n",
    "        '''\n",
    "        target = []\n",
    "        for cls_num, cls in enumerate(self.class_list):\n",
    "            if int(annot[cls]) == 1:\n",
    "                target.append(cls_num)\n",
    "        target = F.one_hot(torch.tensor(target), self.num_classes).sum(dim=0).to(torch.float)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "    \n",
    "    def _get_classes(self):\n",
    "        '''\n",
    "        :return: 클래스의 리스트를 반환한다. 각 인덱스는 클래스 번호가 된다.\n",
    "            예) ['blue', 'shirts', 'dress', ...] => blue: 0번 클래스, shirts: 1번 클래스, ... \n",
    "        '''\n",
    "        class_list = []\n",
    "        columns = self.annotations.columns\n",
    "        for col in columns:\n",
    "            if col != 'filename':\n",
    "                class_list.append(col)\n",
    "        \n",
    "        class_list.sort()\n",
    "        return class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b585c148c1fb6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:34:55.560225Z",
     "start_time": "2024-03-15T02:34:55.438972Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    데이터세트의 출력 값을 시각화 한다.\n",
    "'''\n",
    "dataset = CsvDataset(data_root=data_root,\n",
    "                     image_dir=image_dir,\n",
    "                     annotations=annotations)\n",
    "data = dataset[0]\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1134f914dbeb6d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:34:56.930407Z",
     "start_time": "2024-03-15T02:34:56.905970Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dataset.class_list)\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34402fc230f305a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:31:22.817470Z",
     "start_time": "2024-03-14T13:31:22.817290Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90e4cf6b80b15cf0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 4. 학습 및 검증 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f4d422139f7fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:35:06.781578Z",
     "start_time": "2024-03-15T02:35:06.761932Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    원본 데이터셋을 학습과 검증셋으로 분할한다.\n",
    "'''\n",
    "annotations = annotations.sample(frac=1).reset_index(drop=True)\n",
    "len_annot = len(annotations)\n",
    "train_annot = annotations.iloc[ : int(len_annot * 0.9)]\n",
    "val_annot = annotations.iloc[int(len_annot * 0.9) : ]\n",
    "\n",
    "print(f'학습 데이터 개수 : {len(train_annot)}')\n",
    "print(f'검증 데이터 개수 : {len(val_annot)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b97f673d659f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:35:10.377829Z",
     "start_time": "2024-03-15T02:35:10.362816Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    학습에 필요한 하이퍼파라미터를 선언한다.\n",
    "'''\n",
    "hyper_params = {\n",
    "    'num_epochs': 5,\n",
    "    'lr': 0.0001,\n",
    "    'score_threshold': 0.5, # 모델의 출력값에 대한 임계값\n",
    "    'image_size': 224,\n",
    "    'train_batch_size': 8,\n",
    "    'val_batch_size': 4,\n",
    "    'print_preq': 0.1 # 학습 중 로그 출력 빈도\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f7cb6d9fa5160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:35:16.965184Z",
     "start_time": "2024-03-15T02:35:16.802636Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "'''\n",
    "    이미지 변환 모듈을 적용한 데이터세트의 결과물을 확인한다.\n",
    "'''\n",
    "# 샘플 이미지 변환 모듈 설정\n",
    "sample_transform = transforms.Compose([\n",
    "    transforms.Resize((hyper_params['image_size'], hyper_params['image_size'])),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.ToTensor(), # 테스트 과정에서 사용하지 않음.\n",
    "])\n",
    "sample_dataset = CsvDataset(data_root, image_dir, train_annot, sample_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5e1b8640d91b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:35:20.091670Z",
     "start_time": "2024-03-15T02:35:19.784262Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_images = []\n",
    "targets = []\n",
    "\n",
    "## 데이터세트에서 변환된 이미지와 target 벡터를 불러온다.\n",
    "max_cnt = 8\n",
    "for idx, (image, target) in enumerate(sample_dataset):\n",
    "    if idx == max_cnt:\n",
    "        break\n",
    "    transformed_images.append(image)\n",
    "    targets.append(target.tolist())\n",
    "\n",
    "## 타켓 벡터를 클래스로 변환하고 \n",
    "target_classes = []\n",
    "class_list = sample_dataset.class_list\n",
    "for target in targets:\n",
    "    classes = []\n",
    "    for cls, val in enumerate(target):\n",
    "        if int(val) == 1:\n",
    "            classes.append(class_list[cls])\n",
    "    target_classes.append(classes)\n",
    "\n",
    "draw_images(transformed_images, target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8bd515ab339e80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:35:26.091773Z",
     "start_time": "2024-03-15T02:35:25.909072Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    이미지 변환 모듈을 적용한 학습 및 검증 데이터세트를 생성한다.\n",
    "    학습 및 검증 데이터 로더를 생성한다.\n",
    "'''\n",
    "\n",
    "\n",
    "# 학습 및 검증 이미지 변환 모듈 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((hyper_params['image_size'], hyper_params['image_size'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 학습 데이터세트 및 데이터로더 설정\n",
    "train_dataset = CsvDataset(data_root, image_dir, train_annot, transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=hyper_params['train_batch_size'], shuffle=True)\n",
    "\n",
    "# 검증 데이터세트 및 데이터로더 설정\n",
    "val_dataset = CsvDataset(data_root, image_dir, train_annot, transform)\n",
    "val_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=hyper_params['val_batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896dc8b07148cd82",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b641a554d3d48c1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 6. 모델 생성\n",
    "1) VGG16 모델을 불러온다.</br>\n",
    "2) 클래스 개수에 맞게 출력 레이어를 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b097fea72662a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:35:39.912517Z",
     "start_time": "2024-03-15T02:35:39.257919Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "'''\n",
    "    1. VGG16 모델을 불러온다.\n",
    "    2. 클래스 개수에 맞게 출력 레이어를 변경한다.\n",
    "'''\n",
    "\n",
    "def get_model(num_classes, weight_path=''):\n",
    "    model = models.vgg16(pretrained=True)\n",
    "    model.classifier[-1] = nn.Linear(4096, num_classes, bias=True)\n",
    "    \n",
    "    if weight_path:\n",
    "        model.load_state_dict(torch.load(weight_path, map_location='cpu'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model(num_classes=train_dataset.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec58b4f7be04ca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 7. 모델 학습 및 검증\n",
    "   1) loss함수와 옵티마이저를 설정한다.</br>\n",
    "   2) 학습 루프를 실행한다.</br>\n",
    "   3) 1 epoch 마다 검증 루프를 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bee9e37577239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:05:13.215782Z",
     "start_time": "2024-03-14T13:31:23.977175Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# loss 함수와 옵티마이저 설정\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyper_params['lr'])\n",
    "\n",
    "# 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = hyper_params['num_epochs']\n",
    "model_save_dir = './train_results'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "# 학습\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0.0\n",
    "    print_cnt = int(len(train_dataloader) * hyper_params['print_preq'])\n",
    "\n",
    "    for idx, (images, targets) in enumerate(train_dataloader):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        # 순전파\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # 역전파 및 가중치 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if idx % print_cnt == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "                  f\"Iter [{idx}/{len(train_dataloader)}] \"\n",
    "                  f\"Loss: {running_loss/print_cnt:.4f}\")\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        \n",
    "\n",
    "    # 한 epoch이 끝날 때마다 손실값 출력\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_dataloader):.4f}\")\n",
    "    \n",
    "    # 한 epoch이 끝날 때마다 model weight 저장\n",
    "    model_save_path = os.path.join(model_save_dir, f'{epoch}_model.pth')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "    # F1-score 계산 및 출력\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = torch.sigmoid(model(images))\n",
    "            preds = (outputs > hyper_params['score_threshold']).float()  # threshold 설정, 여기서는 0.5로 가정\n",
    "            y_true.extend(targets.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average='micro')  # F1-score 계산\n",
    "    print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb315b2af5cf2bd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:05:13.218210Z",
     "start_time": "2024-03-14T14:05:13.215336Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9bec7b9169798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:31:46.816179Z",
     "start_time": "2024-03-14T14:31:45.503600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "'''\n",
    "    학습 결과 모델과 하이퍼파라미터를 저장한다.\n",
    "'''\n",
    "\n",
    "model_save_dir = './train_results'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "model_save_path = os.path.join(model_save_dir, 'model.pth')\n",
    "\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "param_save_path = os.path.join(model_save_dir, 'hyper_params.json') \n",
    "with open(param_save_path, 'w')as json_f:\n",
    "    json.dump(hyper_params, json_f, indent='\\t', ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185f4917dc588ab",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66ab2943ab4bd5b7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 8. 모델 테스트\n",
    "1) 학습한 모델의 가중치를 불러온다.</br>\n",
    "2) 모델 추론 결과를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836aed7768c9cc00",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    모델의 추론을 수행한다.\n",
    "'''\n",
    "image_list = []\n",
    "pred_list = []\n",
    "\n",
    "val_cnt = 8\n",
    "iter_cnt = 0\n",
    "for idx, annot in val_annot.iterrows():\n",
    "    if iter_cnt == val_cnt:\n",
    "        break\n",
    "    image_path = os.path.join(data_root, image_dir, annot['filename'])\n",
    "    print(f'image_path : {image_path}')\n",
    "    image = Image.open(image_path)\n",
    "    image_list.append(image)\n",
    "    input_image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    outputs = torch.sigmoid(model(input_image))[0]\n",
    "    preds = (outputs > hyper_params['score_threshold']).int().tolist() # threshold 설정\n",
    "    pred_list.append(preds)\n",
    "    \n",
    "    iter_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5714020a21f189",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    모델의 추론 결과(클래스 번호)를 클래스 이름으로 변경한다\n",
    "'''\n",
    "class_list = train_dataset.class_list\n",
    "pred_class_list = []\n",
    "for pred in pred_list:\n",
    "    pred_class = []\n",
    "    for cls, val in enumerate(pred):\n",
    "        if int(val) == 1:\n",
    "            pred_class.append(class_list[cls])\n",
    "    pred_class_list.append(pred_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6065973205e7d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_images(image_list, pred_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23a4a87251ef7e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac75ba8fd15b7a8d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 9. 검증 데이터의 f1-score를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da5504537dc2e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics(val_dataloader, score_threshold, class_list):\n",
    "    metric_df = pd.DataFrame(columns=['class', 'precision', 'recall', 'f1'])\n",
    "    \n",
    "    # F1-score 계산 및 출력\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = torch.sigmoid(model(images))\n",
    "            preds = (outputs > score_threshold).float()  # threshold 설정, 여기서는 0.5로 가정\n",
    "            y_true.extend(targets.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, average=None)\n",
    "    recall = recall_score(y_true, y_pred, average=None)\n",
    "    f1 = f1_score(y_true, y_pred, average=None)  # F1-score 계산\n",
    "    \n",
    "    metric_df['class'] = class_list\n",
    "    metric_df['precision'] = precision\n",
    "    metric_df['recall'] = recall\n",
    "    metric_df['f1'] = f1\n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02e6bf86358d2f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric_df = calculate_metrics(val_dataloader, hyper_params['score_threshold'], class_list)\n",
    "metric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c95461b6d0832",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e39c184c02d4c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
